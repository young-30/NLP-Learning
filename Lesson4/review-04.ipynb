{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "\n",
    "        raise NotImplemented\n",
    "    \n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        raise NotImplemented  \n",
    "        \n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        An Input node has no inbound nodes.\n",
    "        So no need to pass anything to the Node instantiator.\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        '''\n",
    "        Only input node is the node where the value may be passed\n",
    "        as an argument to forward().\n",
    "        All other node implementations should get the value of the \n",
    "        previous node from self.inbound_nodes\n",
    "        \n",
    "        Example: \n",
    "        val0: self.inbound_nodes[0].value\n",
    "        '''\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            ## It's is input node, when need to forward, this node initiate self's value.\n",
    "\n",
    "        # Input subclass just holds a value, such as a data feature or a model parameter(weight/bias)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}  ## 初始化为0\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1 ## x关于自身求导等于1\n",
    "            \n",
    "        \n",
    "        # input N --> N1, N2\n",
    "        # \\partial L / \\partial N \n",
    "        # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N\n",
    "\n",
    "\n",
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        ## when execute forward, this node caculate value as defined.\n",
    "\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias  # wx+b\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        # initial a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs} # 生成shape相同的全0数组\n",
    "\n",
    "        for n in self.outputs:\n",
    "            # Get the partial of the cost w.r.t this node.\n",
    "            grad_cost = n.gradients[self]  # d(output)/d(z)\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "        # WX + B / W ==> X\n",
    "        # WX + B / X ==> W\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^-x)\n",
    "        # y' = 1 / (1 + e^-x) (1 - 1 / (1 + e^-x))\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  # Get the partial of the cost with respect to this node.\n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to keep all the dimension same!.\n",
    "\n",
    "\n",
    "\n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def forward_and_backward(outputnode, graph):\n",
    "    # execute all the forward method of sorted_nodes.\n",
    "\n",
    "    ## In practice, it's common to feed in mutiple data example in each forward pass rather than just 1. \n",
    "    ## Because the examples can be processed in parallel. The number of examples is called batch size.\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        ## each node execute forward, get self.value based on the topological sort result.\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "    #return outputnode.value\n",
    "\n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.61352356e+00, 1.13636364e+01, 1.11367787e+01, 6.91699605e-02,\n",
       "       5.54695059e-01, 6.28463439e+00, 6.85749012e+01, 3.79504269e+00,\n",
       "       9.54940711e+00, 4.08237154e+02, 1.84555336e+01, 3.56674032e+02,\n",
       "       1.26530632e+01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data['data'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n",
      "Epoch: 1, Loss: 216.491\n",
      "Epoch: 101, Loss: 8.115\n",
      "Epoch: 201, Loss: 6.631\n",
      "Epoch: 301, Loss: 5.838\n",
      "Epoch: 401, Loss: 5.468\n",
      "Epoch: 501, Loss: 4.953\n",
      "Epoch: 601, Loss: 5.732\n",
      "Epoch: 701, Loss: 3.928\n",
      "Epoch: 801, Loss: 4.041\n",
      "Epoch: 901, Loss: 4.960\n",
      "Epoch: 1001, Loss: 4.082\n",
      "Epoch: 1101, Loss: 4.043\n",
      "Epoch: 1201, Loss: 4.812\n",
      "Epoch: 1301, Loss: 4.116\n",
      "Epoch: 1401, Loss: 3.732\n",
      "Epoch: 1501, Loss: 3.880\n",
      "Epoch: 1601, Loss: 3.336\n",
      "Epoch: 1701, Loss: 3.716\n",
      "Epoch: 1801, Loss: 3.070\n",
      "Epoch: 1901, Loss: 3.402\n",
      "Epoch: 2001, Loss: 4.473\n",
      "Epoch: 2101, Loss: 3.261\n",
      "Epoch: 2201, Loss: 2.994\n",
      "Epoch: 2301, Loss: 3.073\n",
      "Epoch: 2401, Loss: 3.529\n",
      "Epoch: 2501, Loss: 3.263\n",
      "Epoch: 2601, Loss: 3.352\n",
      "Epoch: 2701, Loss: 4.067\n",
      "Epoch: 2801, Loss: 3.345\n",
      "Epoch: 2901, Loss: 3.605\n",
      "Epoch: 3001, Loss: 3.010\n",
      "Epoch: 3101, Loss: 2.902\n",
      "Epoch: 3201, Loss: 3.281\n",
      "Epoch: 3301, Loss: 2.926\n",
      "Epoch: 3401, Loss: 3.064\n",
      "Epoch: 3501, Loss: 3.695\n",
      "Epoch: 3601, Loss: 2.977\n",
      "Epoch: 3701, Loss: 3.156\n",
      "Epoch: 3801, Loss: 3.287\n",
      "Epoch: 3901, Loss: 3.188\n",
      "Epoch: 4001, Loss: 2.920\n",
      "Epoch: 4101, Loss: 3.379\n",
      "Epoch: 4201, Loss: 3.339\n",
      "Epoch: 4301, Loss: 3.375\n",
      "Epoch: 4401, Loss: 2.919\n",
      "Epoch: 4501, Loss: 3.003\n",
      "Epoch: 4601, Loss: 3.072\n",
      "Epoch: 4701, Loss: 2.728\n",
      "Epoch: 4801, Loss: 3.308\n",
      "Epoch: 4901, Loss: 3.160\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check out the new network architecture and dataset!\n",
    "Notice that the weights and biases are\n",
    "generated randomly.\n",
    "No need to change anything, but feel free to tweak\n",
    "to test your network, play around with the epochs, batch size, etc!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "#from miniflow import *\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data 归一化,mean是均值，std是标准差,经过处理的数据符合标准正态分布\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)  #(13,10)\n",
    "b1_ = np.zeros(n_hidden) # (1,10)\n",
    "W2_ = np.random.randn(n_hidden, 1) #(10,1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000\n",
    "# Total number of examples\n",
    "m = X_.shape[0]  #506\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size #31\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))\n",
    "\n",
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        sgd_update(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = topological_sort(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Input at 0x2712cec4208>,\n",
       " <__main__.Input at 0x2712cf5b630>,\n",
       " <__main__.Input at 0x2712cf5b6a0>,\n",
       " <__main__.Input at 0x2712cf5bcc0>,\n",
       " <__main__.Input at 0x2712a53ed30>,\n",
       " <__main__.Input at 0x2712cec4748>,\n",
       " <__main__.Linear at 0x2712cf5bd30>,\n",
       " <__main__.Sigmoid at 0x2712cf5bda0>,\n",
       " <__main__.Linear at 0x2712cf5bcf8>,\n",
       " <__main__.MSE at 0x2712cf5bdd8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for j in range(3):\n",
    "    print(1)\n",
    "    X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "    print(X_batch[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.59196870e-01, -4.87722365e-01, -7.20322144e-01,\n",
       "        -2.72598567e-01, -4.37920655e-01,  3.47668804e+00,\n",
       "         5.12964763e-01, -4.28137739e-01, -1.78120388e-01,\n",
       "        -6.01276097e-01, -4.88039145e-01,  2.77682993e-01,\n",
       "        -1.12462313e+00],\n",
       "       [ 2.28969740e-01, -4.87722365e-01,  1.01599907e+00,\n",
       "        -2.72598567e-01,  1.36749033e+00,  2.15644333e-01,\n",
       "         6.87211565e-01, -7.03186322e-01,  1.66124525e+00,\n",
       "         1.53092646e+00,  8.06575835e-01, -2.81218284e+00,\n",
       "         4.99991021e-01],\n",
       "       [-4.15066495e-01, -4.87722365e-01, -1.12740922e+00,\n",
       "        -2.72598567e-01, -5.67495606e-01,  1.88575818e-01,\n",
       "        -8.80089015e-02, -3.34062186e-01, -8.67882504e-01,\n",
       "        -8.21029564e-01, -3.03094148e-01,  3.89300161e-01,\n",
       "        -5.38696714e-01],\n",
       "       [ 1.17124730e+00, -4.87722365e-01,  1.01599907e+00,\n",
       "        -2.72598567e-01,  1.60072524e+00, -4.98109663e-01,\n",
       "         6.87211565e-01, -9.38589120e-01,  1.66124525e+00,\n",
       "         1.53092646e+00,  8.06575835e-01, -3.15470939e+00,\n",
       "         2.99508436e+00],\n",
       "       [ 8.78254408e-01, -4.87722365e-01,  1.01599907e+00,\n",
       "        -2.72598567e-01,  1.60072524e+00,  4.90603458e-01,\n",
       "         9.25467397e-01, -7.94029365e-01,  1.66124525e+00,\n",
       "         1.53092646e+00,  8.06575835e-01, -2.70626713e+00,\n",
       "         1.48821619e+00],\n",
       "       [-4.09852974e-01, -4.87722365e-01, -4.76800599e-02,\n",
       "        -2.72598567e-01, -1.22400869e+00, -3.12904036e-01,\n",
       "        -2.16119024e+00,  7.09373073e-01, -6.37961799e-01,\n",
       "        -6.13154663e-01,  3.44213342e-01,  3.75375426e-01,\n",
       "        -9.99868462e-01],\n",
       "       [ 1.09663902e-01, -4.87722365e-01,  1.01599907e+00,\n",
       "        -2.72598567e-01,  1.41068198e+00, -3.88024936e+00,\n",
       "         6.87211565e-01, -1.03718068e+00,  1.66124525e+00,\n",
       "         1.53092646e+00,  8.06575835e-01, -2.16439901e-02,\n",
       "        -7.75590408e-01],\n",
       "       [-2.43744150e-01, -4.87722365e-01,  1.23194490e+00,\n",
       "         3.66839786e+00,  4.34550682e-01,  2.97805751e+00,\n",
       "         9.00574997e-01, -7.76298096e-01, -5.23001446e-01,\n",
       "        -3.11049400e-02, -1.73641788e+00,  3.48403104e-01,\n",
       "        -1.30825078e+00],\n",
       "       [-1.49252576e-01, -4.87722365e-01,  1.23194490e+00,\n",
       "        -2.72598567e-01,  2.73234648e+00, -1.56517901e+00,\n",
       "         8.97018940e-01, -1.07692154e+00, -5.23001446e-01,\n",
       "        -3.11049400e-02, -1.73641788e+00,  3.46439054e-03,\n",
       "         2.19609380e+00],\n",
       "       [-3.03859070e-01, -4.87722365e-01, -4.37258013e-01,\n",
       "        -2.72598567e-01, -1.44217433e-01,  5.54713098e-01,\n",
       "         6.65875222e-01,  2.11043605e-01, -6.37961799e-01,\n",
       "        -6.01276097e-01,  1.17646583e+00,  2.58276079e-01,\n",
       "        -9.43458210e-02],\n",
       "       [-3.90063706e-01, -4.87722365e-01, -1.80457565e-01,\n",
       "        -2.72598567e-01, -9.23874522e-02, -3.72739700e-01,\n",
       "         7.76112995e-01, -4.56850035e-01, -6.37961799e-01,\n",
       "        -6.19093946e-01, -2.56766523e-02,  4.34473318e-01,\n",
       "        -1.30791005e-01],\n",
       "       [-4.01652153e-01,  3.70668997e-01, -6.09431041e-01,\n",
       "        -2.72598567e-01, -7.83453857e-01, -6.35887672e-02,\n",
       "        -1.85892538e+00,  3.01363742e-01, -7.52922151e-01,\n",
       "        -1.10017586e+00,  6.67958463e-02,  4.41051933e-01,\n",
       "        -8.49882513e-01],\n",
       "       [-3.57149865e-01, -4.87722365e-01,  1.56899549e+00,\n",
       "        -2.72598567e-01,  5.98678953e-01, -1.90383389e-01,\n",
       "         1.04281728e+00, -1.01079769e+00, -6.37961799e-01,\n",
       "         1.70830678e-01,  1.26893833e+00,  4.41051933e-01,\n",
       "         8.13980295e-01],\n",
       "       [ 2.38896377e-01, -4.87722365e-01,  1.01599907e+00,\n",
       "        -2.72598567e-01,  1.60072524e+00, -9.35065994e-02,\n",
       "         1.11749449e+00, -8.51026125e-01,  1.66124525e+00,\n",
       "         1.53092646e+00,  8.06575835e-01,  4.27785059e-01,\n",
       "         5.51855320e-01],\n",
       "       [-3.96034817e-01,  3.70668997e-01, -1.13908197e+00,\n",
       "        -2.72598567e-01, -9.65722622e-01,  7.51315996e-01,\n",
       "        -1.29351229e+00,  1.45300053e-01, -5.23001446e-01,\n",
       "        -1.14175084e+00, -1.64394538e+00,  4.41051933e-01,\n",
       "        -1.09378490e+00],\n",
       "       [-4.03956343e-01, -4.87722365e-01, -1.64407537e-01,\n",
       "        -2.72598567e-01, -6.64724620e-02, -4.36435457e-02,\n",
       "         5.55637449e-01, -7.31375712e-01, -4.08041094e-01,\n",
       "         1.41134264e-01, -3.03094148e-01,  3.51582768e-01,\n",
       "        -3.08811710e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41978194,  0.28482986, -1.2879095 , ..., -1.45900038,\n",
       "         0.44105193, -1.0755623 ],\n",
       "       [-0.41733926, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.44105193, -0.49243937],\n",
       "       [-0.41734159, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.39642699, -1.2087274 ],\n",
       "       ...,\n",
       "       [-0.41344658, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.98304761],\n",
       "       [-0.40776407, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.4032249 , -0.86530163],\n",
       "       [-0.41500016, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.66905833]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
